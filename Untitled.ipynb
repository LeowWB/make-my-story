{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "complicated-representative",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\thisi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\thisi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk.corpus\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn import metrics\n",
    "from pdb import set_trace as st\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bright-question",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstopwords = stopwords + [\\n    \"n\\'t\",\\n    \\'not\\',\\n    \\'mr\\',\\n    \\'mr.\\'\\n]\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "'''\n",
    "stopwords = stopwords + [\n",
    "    \"n't\",\n",
    "    'not',\n",
    "    'mr',\n",
    "    'mr.'\n",
    "]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "western-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('train.csv', newline='', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, dialect='excel')\n",
    "    train_set = list(reader)\n",
    "\n",
    "train_set = list(map(\n",
    "    lambda x: [int(x[0]), x[1], int(x[2])],\n",
    "    train_set[1:]\n",
    "))\n",
    "\n",
    "random.shuffle(train_set)\n",
    "\n",
    "for datum in train_set:\n",
    "    if datum[2] == -1:\n",
    "        datum.append([1,0,0])\n",
    "    elif datum[2] == 0:\n",
    "        datum.append([0,1,0])\n",
    "    else:\n",
    "        datum.append([0,0,1])\n",
    "\n",
    "val_set = train_set[:2000]\n",
    "train_set = train_set[2000:]\n",
    "\n",
    "with open('test.csv', newline='', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, dialect='excel')\n",
    "    test_set = list(reader)\n",
    "\n",
    "test_set = list(map(\n",
    "    lambda x: (int(x[0]), x[1]),\n",
    "    test_set[1:]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "included-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_tokens(string):\n",
    "    tokens = word_tokenize(string)\n",
    "    tokens = filter(\n",
    "        lambda x: re.match(re.compile(r\"^[A-Za-z'][A-Za-z'.]*$\"), x),\n",
    "        tokens\n",
    "    )\n",
    "    tokens = map(\n",
    "        lambda x: x.lower(),\n",
    "        tokens\n",
    "    )\n",
    "    tokens = filter(\n",
    "        lambda x: x not in stopwords and x[0] != \"'\",\n",
    "        tokens\n",
    "    )\n",
    "    return list(tokens)\n",
    "\n",
    "def remove_unknown_words(vocab, tokens):\n",
    "    return list(filter(\n",
    "        lambda x: x in vocab,\n",
    "        tokens\n",
    "    ))\n",
    "\n",
    "def generate_word_counts(train_set):\n",
    "    word_counts = {}\n",
    "    for train_datum in train_set:\n",
    "        for word in string_to_tokens(train_datum[1]):\n",
    "            word_counts[word] = word_counts.get(word, 0) + 1\n",
    "    return word_counts\n",
    "\n",
    "def remove_rare_words_from_word_counts(word_counts, threshold=5):\n",
    "    new_dict = {}\n",
    "    for word in word_counts.keys():\n",
    "        if word_counts[word] >= threshold:\n",
    "            new_dict[word] = word_counts[word]\n",
    "    return new_dict\n",
    "\n",
    "# returns a dict that maps words to integers. will be used for encoding text.\n",
    "def generate_wordmap(words):\n",
    "    wordmap = {}\n",
    "    for i in range(len(words)):\n",
    "        wordmap[words[i]] = i\n",
    "    return wordmap\n",
    "\n",
    "def string_to_vector(string, wordmap):\n",
    "    tokens = string_to_tokens(string)\n",
    "    tokens = remove_unknown_words(wordmap.keys(), tokens)\n",
    "    result = np.zeros(len(wordmap))\n",
    "    for token in tokens:\n",
    "        result[wordmap[token]] += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "peaceful-capacity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10504\n"
     ]
    }
   ],
   "source": [
    "word_counts = generate_word_counts(train_set)\n",
    "print(len(word_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "laden-bedroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b088ea9908>]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_counts = remove_rare_words_from_word_counts(word_counts)\n",
    "print(len(word_counts.keys()))\n",
    "plt.plot(sorted(word_counts.values(), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "adapted-garbage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"n't\", 2506),\n",
       " ('people', 1971),\n",
       " ('think', 1789),\n",
       " ('going', 1607),\n",
       " ('president', 1424),\n",
       " ('would', 1372),\n",
       " ('one', 1111),\n",
       " ('get', 1047),\n",
       " ('make', 994),\n",
       " ('want', 986),\n",
       " ('know', 934),\n",
       " ('said', 927),\n",
       " ('country', 907),\n",
       " ('uh', 899),\n",
       " ('years', 859),\n",
       " ('got', 799),\n",
       " ('us', 774),\n",
       " ('well', 765),\n",
       " ('tax', 704),\n",
       " ('america', 701)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = [(k, v) for k, v in word_counts.items()]\n",
    "top_n = sorted(\n",
    "    pairs, key=lambda item: -item[1]\n",
    ")\n",
    "top_n[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "composed-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordmap = generate_wordmap(list(word_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "endangered-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: dropout?\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_dims):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dims, 500)\n",
    "        self.layer2 = nn.Linear(500, 75)\n",
    "        self.layer3 = nn.Linear(75, 3)\n",
    "\n",
    "    # Called on each input\n",
    "    # Computes the outputs (and next hidden state)\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = nn.Softmax(dim=3)(x)\n",
    "        return x[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "running-relief",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3513, 0.3264, 0.3223]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net = NeuralNet(len(wordmap))\n",
    "neural_net(torch.Tensor([[[string_to_vector('president think say',wordmap)]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "recent-salem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3530, 0.3244, 0.3226]], grad_fn=<SelectBackward>), 1)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net(torch.Tensor([[[string_to_vector(train_set[0][1],wordmap)]]])), train_set[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dimensional-sitting",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'st' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-5b60c14698d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         ))]])\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mst\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneural_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'st' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(neural_net.parameters(), lr=0.001, momentum=0.9)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        _, x, labels, _ = data\n",
    "        \n",
    "        x = torch.FloatTensor([[list(map(\n",
    "            lambda string: string_to_vector(string, wordmap),\n",
    "            x\n",
    "        ))]])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = neural_net(x)\n",
    "        loss = criterion(outputs, torch.LongTensor(labels))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "elder-istanbul",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE Loss: 1.0901960134506226\n",
      "Macro F1: 0.2633595482960274\n",
      "--Return--\n",
      "None\n",
      "> \u001b[1;32m<ipython-input-112-7bbcda7f7fc7>\u001b[0m(23)\u001b[0;36mvalidate\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     21 \u001b[1;33m    \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Macro F1: {metrics.f1_score(val_y_labels, val_output_labels, average=\"macro\")}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     22 \u001b[1;33m    \u001b[1;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 23 \u001b[1;33m    \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     24 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     25 \u001b[1;33m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneural_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> val_outputs\n",
      "tensor([[0.3515, 0.3248, 0.3237],\n",
      "        [0.3533, 0.3258, 0.3209],\n",
      "        [0.3499, 0.3273, 0.3228],\n",
      "        ...,\n",
      "        [0.3516, 0.3255, 0.3229],\n",
      "        [0.3505, 0.3272, 0.3224],\n",
      "        [0.3504, 0.3273, 0.3223]], grad_fn=<SelectBackward>)\n",
      "ipdb> val_y_labels\n",
      "[2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 0, 0, 0, 0, 2, 1, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 1, 2, 0, 2, 0, 2, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 1, 0, 2, 2, 0, 1, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 2, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 2, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 2, 2, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 1, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 2, 2, 2, 0, 1, 0, 1, 2, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 0, 1, 0, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 2, 2, 0, 0, 2, 2, 1, 0, 2, 0, 0, 2, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 2, 2, 2, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 2, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 2, 0, 1, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 1, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 1, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 2, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 1, 2, 0, 0, 1, 0, 0, 0, 2, 0, 2, 1, 2, 0, 2, 2, 0, 1, 2, 2, 0, 2, 0, 0, 2, 2, 1, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 0, 0, 0, 1, 0, 0, 1, 1, 2, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 1, 1, 0, 0, 0, 1, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 1, 0, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 2, 0, 1, 0, 0, 2, 1, 1, 2, 0, 2, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 1, 2, 0, 2, 2, 0, 0, 2, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 1, 0, 1, 2, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2, 1, 0, 0, 0, 2, 1, 0, 2, 1, 2, 0, 1, 2, 0, 2, 0, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 2, 0, 0, 1, 0, 0, 2, 0, 0, 1, 0, 2, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 1, 2, 0, 1, 1, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 0, 1, 1, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 0, 0, 2, 1, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 1, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 1, 0, 2, 2, 0, 0, 2, 1, 0, 0, 0, 0, 2, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 1, 0, 2, 0, 1, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 1, 1, 2, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 0, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0, 1, 0, 0, 2, 2, 2, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 1, 2, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 1, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 2, 0, 2, 1, 2, 0, 0, 0, 2, 0, 2, 0, 2, 1, 2, 2, 0, 0, 2, 0, 0, 1, 2, 2, 0, 0, 1, 0, 2, 0, 1, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 1, 0, 1, 1, 0, 0, 1, 1, 2, 2, 2, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 0, 0, 1, 0, 2, 0, 2, 0, 1, 0, 0, 0, 2, 1, 0, 2, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 2, 0, 1, 0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 2, 0, 2, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 1, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 2, 0, 0, 2, 2, 1, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 1, 2, 0, 2, 1, 2, 1, 0, 0, 1, 1, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 1, 2, 0, 2, 0, 0, 0, 2, 1, 0, 2, 2, 0, 1, 2, 0, 0, 2, 1]\n",
      "ipdb> val_output_labels\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-7bbcda7f7fc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneural_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-112-7bbcda7f7fc7>\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(model, val_set)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Macro F1: {metrics.f1_score(val_y_labels, val_output_labels, average=\"macro\")}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneural_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python3.6\\lib\\bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'return'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_return\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'exception'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python3.6\\lib\\bdb.py\u001b[0m in \u001b[0;36mdispatch_return\u001b[1;34m(self, frame, arg)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe_returning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m             \u001b[1;31m# The user issued a 'next' or 'until' command.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopframe\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstoplineno\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def validate(model, val_set):\n",
    "    val_x = []\n",
    "    val_y_labels = []\n",
    "    for val_datum in val_set:\n",
    "        val_x.append(val_datum[1])\n",
    "        val_y_labels.append(val_datum[2]+1)\n",
    "    val_x = torch.FloatTensor([[list(map(\n",
    "        lambda string: string_to_vector(string, wordmap),\n",
    "        val_x\n",
    "    ))]])\n",
    "    val_outputs = neural_net(val_x)\n",
    "    loss = criterion(val_outputs, torch.LongTensor(val_y_labels))\n",
    "    print(f'CE Loss: {loss.item()}')\n",
    "    \n",
    "    val_output_labels = list(map(\n",
    "        lambda v_o: np.argmax(v_o.detach().numpy()),\n",
    "        val_outputs\n",
    "    ))\n",
    "    print(f'Macro F1: {metrics.f1_score(val_y_labels, val_output_labels, average=\"macro\")}')\n",
    "        \n",
    "validate(neural_net, val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "technological-estimate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5514)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
