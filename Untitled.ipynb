{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "complicated-representative",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk.corpus\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn import metrics\n",
    "from pdb import set_trace as st\n",
    "import spacy\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-harvard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-museum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bright-question",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstopwords = stopwords + [\\n    \"n\\'t\",\\n    \\'not\\',\\n    \\'mr\\',\\n    \\'mr.\\'\\n]\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")  # make sure to use larger package!\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "'''\n",
    "stopwords = stopwords + [\n",
    "    \"n't\",\n",
    "    'not',\n",
    "    'mr',\n",
    "    'mr.'\n",
    "]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "western-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('train.csv', newline='', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, dialect='excel')\n",
    "    train_set = list(reader)\n",
    "\n",
    "train_set = list(map(\n",
    "    lambda x: [int(x[0]), x[1], int(x[2])],\n",
    "    train_set[1:]\n",
    "))\n",
    "\n",
    "random.shuffle(train_set)\n",
    "\n",
    "for datum in train_set:\n",
    "    if datum[2] == -1:\n",
    "        datum.append(np.array([1,0,0]))\n",
    "    elif datum[2] == 0:\n",
    "        datum.append(np.array([0,1,0]))\n",
    "    else:\n",
    "        datum.append(np.array([0,0,1]))\n",
    "\n",
    "val_set = train_set[:2000]\n",
    "train_set = train_set[2000:]\n",
    "\n",
    "# class weight code goes here.\n",
    "\n",
    "with open('test.csv', newline='', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, dialect='excel')\n",
    "    test_set = list(reader)\n",
    "\n",
    "test_set = list(map(\n",
    "    lambda x: (int(x[0]), x[1]),\n",
    "    test_set[1:]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "scenic-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_label_counts = np.sum(\n",
    "    np.array(list(map(\n",
    "        lambda x: x[3],\n",
    "        train_set\n",
    "    ))),\n",
    "    axis=0\n",
    ")\n",
    "class_weights = np.array([10000, 10000, 10000]) / train_set_label_counts\n",
    "class_weights = torch.FloatTensor(class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "included-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_tokens(string):\n",
    "    tokens = word_tokenize(string)\n",
    "    tokens = filter(\n",
    "        lambda x: re.match(re.compile(r\"^[A-Za-z'][A-Za-z'.]*$\"), x),\n",
    "        tokens\n",
    "    )\n",
    "    tokens = map(\n",
    "        lambda x: x.lower(),\n",
    "        tokens\n",
    "    )\n",
    "    tokens = filter(\n",
    "        lambda x: x not in stopwords and x[0] != \"'\",\n",
    "        tokens\n",
    "    )\n",
    "    return list(tokens)\n",
    "\n",
    "def remove_unknown_words(vocab, tokens):\n",
    "    return list(filter(\n",
    "        lambda x: x in vocab,\n",
    "        tokens\n",
    "    ))\n",
    "\n",
    "def generate_word_counts(train_set):\n",
    "    word_counts = {}\n",
    "    for train_datum in train_set:\n",
    "        for word in string_to_tokens(train_datum[1]):\n",
    "            word_counts[word] = word_counts.get(word, 0) + 1\n",
    "    return word_counts\n",
    "\n",
    "def remove_rare_words_from_word_counts(word_counts, threshold=5):\n",
    "    new_dict = {}\n",
    "    for word in word_counts.keys():\n",
    "        if word_counts[word] >= threshold:\n",
    "            new_dict[word] = word_counts[word]\n",
    "    return new_dict\n",
    "\n",
    "# returns a dict that maps words to integers. will be used for encoding text.\n",
    "def generate_wordmap(words):\n",
    "    wordmap = {}\n",
    "    for i in range(len(words)):\n",
    "        wordmap[words[i]] = i\n",
    "    return wordmap\n",
    "\n",
    "def string_to_vector(string, wordmap):\n",
    "    tokens = string_to_tokens(string)\n",
    "    tokens = remove_unknown_words(wordmap.keys(), tokens)\n",
    "    result = np.zeros(len(wordmap))\n",
    "    for token in tokens:\n",
    "        result[wordmap[token]] += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "peaceful-capacity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10484\n"
     ]
    }
   ],
   "source": [
    "word_counts = generate_word_counts(train_set)\n",
    "print(len(word_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "laden-bedroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13de42c4390>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_counts = remove_rare_words_from_word_counts(word_counts)\n",
    "print(len(word_counts.keys()))\n",
    "plt.plot(sorted(word_counts.values(), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "adapted-garbage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"n't\", 2501),\n",
       " ('people', 1983),\n",
       " ('think', 1764),\n",
       " ('going', 1623),\n",
       " ('would', 1403),\n",
       " ('president', 1393),\n",
       " ('one', 1081),\n",
       " ('get', 1052),\n",
       " ('make', 990),\n",
       " ('want', 956),\n",
       " ('know', 947),\n",
       " ('country', 913),\n",
       " ('said', 908),\n",
       " ('uh', 906),\n",
       " ('years', 843),\n",
       " ('got', 812),\n",
       " ('us', 775),\n",
       " ('well', 756),\n",
       " ('say', 738),\n",
       " ('tax', 713)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = [(k, v) for k, v in word_counts.items()]\n",
    "top_n = sorted(\n",
    "    pairs, key=lambda item: -item[1]\n",
    ")\n",
    "top_n[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "composed-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordmap = generate_wordmap(list(word_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "endangered-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: dropout?\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_dims):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dims, 50)\n",
    "        self.layer2 = nn.Linear(50, 10)\n",
    "        self.layer3 = nn.Linear(10, 3)\n",
    "\n",
    "    # Called on each input\n",
    "    # Computes the outputs (and next hidden state)\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = nn.Softmax(dim=3)(x)\n",
    "        return x[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "running-relief",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2891, 0.3075, 0.4034]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net = NeuralNet(300)\n",
    "neural_net(torch.Tensor([[[nlp('president think say').vector]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "recent-salem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2932, 0.3073, 0.3994]], grad_fn=<SelectBackward>), -1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net(torch.Tensor([[[nlp(train_set[0][1]).vector]]])), train_set[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dimensional-sitting",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.081\n",
      "[1,  4000] loss: 1.061\n",
      "Epoch 0\n",
      "CE Loss: 1.0871683359146118\n",
      "Macro F1: 0.30876303145053924\n",
      "[2,  2000] loss: 0.993\n",
      "[2,  4000] loss: 0.943\n",
      "Epoch 1\n",
      "CE Loss: 0.997660219669342\n",
      "Macro F1: 0.4931348174197974\n",
      "[3,  2000] loss: 0.926\n",
      "[3,  4000] loss: 0.914\n",
      "Epoch 2\n",
      "CE Loss: 0.9946256279945374\n",
      "Macro F1: 0.499371992101972\n",
      "[4,  2000] loss: 0.907\n",
      "[4,  4000] loss: 0.914\n",
      "Epoch 3\n",
      "CE Loss: 0.9812584519386292\n",
      "Macro F1: 0.4998371439113452\n",
      "[5,  2000] loss: 0.912\n",
      "[5,  4000] loss: 0.918\n",
      "Epoch 4\n",
      "CE Loss: 0.9793031215667725\n",
      "Macro F1: 0.4988833500370095\n",
      "[6,  2000] loss: 0.913\n",
      "[6,  4000] loss: 0.893\n",
      "Epoch 5\n",
      "CE Loss: 0.9572290182113647\n",
      "Macro F1: 0.5260974151554726\n",
      "[7,  2000] loss: 0.901\n",
      "[7,  4000] loss: 0.890\n",
      "Epoch 6\n",
      "CE Loss: 0.9197705388069153\n",
      "Macro F1: 0.6201296463378344\n",
      "[8,  2000] loss: 0.874\n",
      "[8,  4000] loss: 0.862\n",
      "Epoch 7\n",
      "CE Loss: 0.8938785195350647\n",
      "Macro F1: 0.601304673899504\n",
      "[9,  2000] loss: 0.867\n",
      "[9,  4000] loss: 0.855\n",
      "Epoch 8\n",
      "CE Loss: 0.8831310272216797\n",
      "Macro F1: 0.6432566616390146\n",
      "[10,  2000] loss: 0.856\n",
      "[10,  4000] loss: 0.851\n",
      "Epoch 9\n",
      "CE Loss: 0.8866620063781738\n",
      "Macro F1: 0.6296768888466621\n",
      "[11,  2000] loss: 0.849\n",
      "[11,  4000] loss: 0.858\n",
      "Epoch 10\n",
      "CE Loss: 0.9007865786552429\n",
      "Macro F1: 0.6124452993827642\n",
      "[12,  2000] loss: 0.853\n",
      "[12,  4000] loss: 0.850\n",
      "Epoch 11\n",
      "CE Loss: 0.8748128414154053\n",
      "Macro F1: 0.6344179810616203\n",
      "[13,  2000] loss: 0.847\n",
      "[13,  4000] loss: 0.842\n",
      "Epoch 12\n",
      "CE Loss: 0.8715178966522217\n",
      "Macro F1: 0.6391971905390963\n",
      "[14,  2000] loss: 0.852\n",
      "[14,  4000] loss: 0.844\n",
      "Epoch 13\n",
      "CE Loss: 0.9085542559623718\n",
      "Macro F1: 0.6422443665685071\n",
      "[15,  2000] loss: 0.841\n",
      "[15,  4000] loss: 0.840\n",
      "Epoch 14\n",
      "CE Loss: 0.8817026615142822\n",
      "Macro F1: 0.6491402909252637\n",
      "[16,  2000] loss: 0.847\n",
      "[16,  4000] loss: 0.838\n",
      "Epoch 15\n",
      "CE Loss: 0.8985089063644409\n",
      "Macro F1: 0.63394268797992\n",
      "[17,  2000] loss: 0.841\n",
      "[17,  4000] loss: 0.843\n",
      "Epoch 16\n",
      "CE Loss: 0.8660858273506165\n",
      "Macro F1: 0.6225681312809113\n",
      "[18,  2000] loss: 0.836\n",
      "[18,  4000] loss: 0.846\n",
      "Epoch 17\n",
      "CE Loss: 0.8828263878822327\n",
      "Macro F1: 0.6487763694431569\n",
      "[19,  2000] loss: 0.840\n",
      "[19,  4000] loss: 0.843\n",
      "Epoch 18\n",
      "CE Loss: 0.8732332587242126\n",
      "Macro F1: 0.6393071249966483\n",
      "[20,  2000] loss: 0.841\n",
      "[20,  4000] loss: 0.829\n",
      "Epoch 19\n",
      "CE Loss: 0.864202618598938\n",
      "Macro F1: 0.6410397478827766\n",
      "[21,  2000] loss: 0.831\n",
      "[21,  4000] loss: 0.844\n",
      "Epoch 20\n",
      "CE Loss: 0.8933606147766113\n",
      "Macro F1: 0.6413011957848914\n",
      "[22,  2000] loss: 0.838\n",
      "[22,  4000] loss: 0.839\n",
      "Epoch 21\n",
      "CE Loss: 0.878413736820221\n",
      "Macro F1: 0.650569685925027\n",
      "[23,  2000] loss: 0.835\n",
      "[23,  4000] loss: 0.837\n",
      "Epoch 22\n",
      "CE Loss: 0.8878660798072815\n",
      "Macro F1: 0.6377553646712458\n",
      "[24,  2000] loss: 0.836\n",
      "[24,  4000] loss: 0.835\n",
      "Epoch 23\n",
      "CE Loss: 0.9220542311668396\n",
      "Macro F1: 0.5419534619152864\n",
      "[25,  2000] loss: 0.834\n",
      "[25,  4000] loss: 0.835\n",
      "Epoch 24\n",
      "CE Loss: 0.8672680854797363\n",
      "Macro F1: 0.6489012247633902\n",
      "[26,  2000] loss: 0.832\n",
      "[26,  4000] loss: 0.835\n",
      "Epoch 25\n",
      "CE Loss: 0.8895295858383179\n",
      "Macro F1: 0.6646056724897089\n",
      "[27,  2000] loss: 0.835\n",
      "[27,  4000] loss: 0.834\n",
      "Epoch 26\n",
      "CE Loss: 0.9035802483558655\n",
      "Macro F1: 0.6078539653581717\n",
      "[28,  2000] loss: 0.830\n",
      "[28,  4000] loss: 0.836\n",
      "Epoch 27\n",
      "CE Loss: 0.8773755431175232\n",
      "Macro F1: 0.6555533702957866\n",
      "[29,  2000] loss: 0.845\n",
      "[29,  4000] loss: 0.834\n",
      "Epoch 28\n",
      "CE Loss: 0.8867395520210266\n",
      "Macro F1: 0.6600271967607103\n",
      "[30,  2000] loss: 0.831\n",
      "[30,  4000] loss: 0.834\n",
      "Epoch 29\n",
      "CE Loss: 0.8863251805305481\n",
      "Macro F1: 0.6525714854567428\n",
      "[31,  2000] loss: 0.834\n",
      "[31,  4000] loss: 0.826\n",
      "Epoch 30\n",
      "CE Loss: 0.8656344413757324\n",
      "Macro F1: 0.6425931155034936\n",
      "[32,  2000] loss: 0.829\n",
      "[32,  4000] loss: 0.832\n",
      "Epoch 31\n",
      "CE Loss: 0.8994067311286926\n",
      "Macro F1: 0.6209590205500833\n",
      "[33,  2000] loss: 0.833\n",
      "[33,  4000] loss: 0.824\n",
      "Epoch 32\n",
      "CE Loss: 0.8729369640350342\n",
      "Macro F1: 0.6263456123986099\n",
      "[34,  2000] loss: 0.834\n",
      "[34,  4000] loss: 0.826\n",
      "Epoch 33\n",
      "CE Loss: 0.8799900412559509\n",
      "Macro F1: 0.6319726720806039\n",
      "[35,  2000] loss: 0.822\n",
      "[35,  4000] loss: 0.831\n",
      "Epoch 34\n",
      "CE Loss: 0.9060657620429993\n",
      "Macro F1: 0.6376954266328214\n",
      "[36,  2000] loss: 0.824\n",
      "[36,  4000] loss: 0.835\n",
      "Epoch 35\n",
      "CE Loss: 0.8743705749511719\n",
      "Macro F1: 0.6591610064553909\n",
      "[37,  2000] loss: 0.827\n",
      "[37,  4000] loss: 0.831\n",
      "Epoch 36\n",
      "CE Loss: 0.8691766858100891\n",
      "Macro F1: 0.6380088193070129\n",
      "[38,  2000] loss: 0.829\n",
      "[38,  4000] loss: 0.815\n",
      "Epoch 37\n",
      "CE Loss: 0.9176847338676453\n",
      "Macro F1: 0.6035361373380549\n",
      "[39,  2000] loss: 0.831\n",
      "[39,  4000] loss: 0.828\n",
      "Epoch 38\n",
      "CE Loss: 0.8762528300285339\n",
      "Macro F1: 0.6505615836593414\n",
      "[40,  2000] loss: 0.823\n",
      "[40,  4000] loss: 0.825\n",
      "Epoch 39\n",
      "CE Loss: 0.8674034476280212\n",
      "Macro F1: 0.6552774715175894\n",
      "[41,  2000] loss: 0.828\n",
      "[41,  4000] loss: 0.826\n",
      "Epoch 40\n",
      "CE Loss: 0.8646600842475891\n",
      "Macro F1: 0.6307602886154398\n",
      "[42,  2000] loss: 0.818\n",
      "[42,  4000] loss: 0.829\n",
      "Epoch 41\n",
      "CE Loss: 0.8823011517524719\n",
      "Macro F1: 0.6353097778772101\n",
      "[43,  2000] loss: 0.836\n",
      "[43,  4000] loss: 0.823\n",
      "Epoch 42\n",
      "CE Loss: 0.8623203039169312\n",
      "Macro F1: 0.6404620082239277\n",
      "[44,  2000] loss: 0.821\n",
      "[44,  4000] loss: 0.828\n",
      "Epoch 43\n",
      "CE Loss: 0.9026330709457397\n",
      "Macro F1: 0.6325355430375827\n",
      "[45,  2000] loss: 0.833\n",
      "[45,  4000] loss: 0.821\n",
      "Epoch 44\n",
      "CE Loss: 0.8781247735023499\n",
      "Macro F1: 0.6614177683146066\n",
      "[46,  2000] loss: 0.825\n",
      "[46,  4000] loss: 0.822\n",
      "Epoch 45\n",
      "CE Loss: 0.8771560192108154\n",
      "Macro F1: 0.653967224191884\n",
      "[47,  2000] loss: 0.825\n",
      "[47,  4000] loss: 0.825\n",
      "Epoch 46\n",
      "CE Loss: 0.8614117503166199\n",
      "Macro F1: 0.6357563630862618\n",
      "[48,  2000] loss: 0.826\n",
      "[48,  4000] loss: 0.820\n",
      "Epoch 47\n",
      "CE Loss: 0.8658304810523987\n",
      "Macro F1: 0.6427520429257624\n",
      "[49,  2000] loss: 0.828\n",
      "[49,  4000] loss: 0.821\n",
      "Epoch 48\n",
      "CE Loss: 0.8744277358055115\n",
      "Macro F1: 0.6282060434616111\n",
      "[50,  2000] loss: 0.825\n",
      "[50,  4000] loss: 0.819\n",
      "Epoch 49\n",
      "CE Loss: 0.9153966903686523\n",
      "Macro F1: 0.6236744347064922\n"
     ]
    }
   ],
   "source": [
    "FORCE_OVERFIT = False\n",
    "\n",
    "if FORCE_OVERFIT:\n",
    "    so_called_train_set = train_set[:4]\n",
    "    epochs = 100\n",
    "else:\n",
    "    so_called_train_set = train_set\n",
    "    epochs = 50\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.SGD(neural_net.parameters(), lr=0.001, momentum=0.9)\n",
    "train_loader = torch.utils.data.DataLoader(so_called_train_set, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        _, x, labels, _ = data\n",
    "        \n",
    "        x = torch.FloatTensor([[list(map(\n",
    "            lambda string: nlp(string).vector,\n",
    "            x\n",
    "        ))]])\n",
    "        \n",
    "        labels = list(map(\n",
    "            lambda x: x+1,\n",
    "            labels\n",
    "        ))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = neural_net(x)\n",
    "        loss = criterion(outputs, torch.LongTensor(labels))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    print(f'Epoch {epoch}')\n",
    "    validate(neural_net, val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "elder-istanbul",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.7789262533187866\n",
      "Macro F1: 0.6236744347064922\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def validate(model, val_set):\n",
    "    val_x = []\n",
    "    val_y_labels = []\n",
    "    for val_datum in val_set:\n",
    "        val_x.append(val_datum[1])\n",
    "        val_y_labels.append(val_datum[2]+1)\n",
    "    val_x = torch.FloatTensor([[list(map(\n",
    "        lambda string: nlp(string).vector,\n",
    "        val_x\n",
    "    ))]])\n",
    "    val_outputs = neural_net(val_x)\n",
    "    loss = criterion(val_outputs, torch.LongTensor(val_y_labels))\n",
    "    print(f'CE Loss: {loss.item()}')\n",
    "    \n",
    "    val_output_labels = list(map(\n",
    "        lambda v_o: np.argmax(v_o.detach().numpy()),\n",
    "        val_outputs\n",
    "    ))\n",
    "    print(f'Macro F1: {metrics.f1_score(val_y_labels, val_output_labels, average=\"macro\")}')\n",
    "        \n",
    "validate(neural_net, val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-estimate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
