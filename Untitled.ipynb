{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complicated-representative",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\thisi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\thisi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk.corpus\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn import metrics\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bright-question",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstopwords = stopwords + [\\n    \"n\\'t\",\\n    \\'not\\',\\n    \\'mr\\',\\n    \\'mr.\\'\\n]\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "'''\n",
    "stopwords = stopwords + [\n",
    "    \"n't\",\n",
    "    'not',\n",
    "    'mr',\n",
    "    'mr.'\n",
    "]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "western-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('train.csv', newline='', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, dialect='excel')\n",
    "    train_set = list(reader)\n",
    "\n",
    "train_set = list(map(\n",
    "    lambda x: (int(x[0]), x[1], int(x[2])),\n",
    "    train_set[1:]\n",
    "))\n",
    "\n",
    "random.shuffle(train_set)\n",
    "val_set = train_set[:2000]\n",
    "train_set = train_set[2000:]\n",
    "\n",
    "with open('test.csv', newline='', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, dialect='excel')\n",
    "    test_set = list(reader)\n",
    "\n",
    "test_set = list(map(\n",
    "    lambda x: (int(x[0]), x[1]),\n",
    "    test_set[1:]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "included-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_tokens(string):\n",
    "    tokens = word_tokenize(string)\n",
    "    tokens = filter(\n",
    "        lambda x: re.match(re.compile(r\"^[A-Za-z'][A-Za-z'.]*$\"), x),\n",
    "        tokens\n",
    "    )\n",
    "    tokens = map(\n",
    "        lambda x: x.lower(),\n",
    "        tokens\n",
    "    )\n",
    "    tokens = filter(\n",
    "        lambda x: x not in stopwords and x[0] != \"'\",\n",
    "        tokens\n",
    "    )\n",
    "    return list(tokens)\n",
    "\n",
    "def remove_unknown_words(vocab, tokens):\n",
    "    return list(filter(\n",
    "        lambda x: x in vocab,\n",
    "        tokens\n",
    "    ))\n",
    "\n",
    "def generate_word_counts(train_set):\n",
    "    word_counts = {}\n",
    "    for train_datum in train_set:\n",
    "        for word in string_to_tokens(train_datum[1]):\n",
    "            word_counts[word] = word_counts.get(word, 0) + 1\n",
    "    return word_counts\n",
    "\n",
    "def remove_rare_words_from_word_counts(word_counts, threshold=5):\n",
    "    new_dict = {}\n",
    "    for word in word_counts.keys():\n",
    "        if word_counts[word] >= threshold:\n",
    "            new_dict[word] = word_counts[word]\n",
    "    return new_dict\n",
    "\n",
    "# returns a dict that maps words to integers. will be used for encoding text.\n",
    "def generate_wordmap(words):\n",
    "    wordmap = {}\n",
    "    for i in range(len(words)):\n",
    "        wordmap[words[i]] = i\n",
    "    return wordmap\n",
    "\n",
    "def string_to_vector(string, wordmap):\n",
    "    tokens = string_to_tokens(string)\n",
    "    tokens = remove_unknown_words(wordmap.keys(), tokens)\n",
    "    result = np.zeros(len(wordmap))\n",
    "    for token in tokens:\n",
    "        result[wordmap[token]] += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "peaceful-capacity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10458\n"
     ]
    }
   ],
   "source": [
    "word_counts = generate_word_counts(train_set)\n",
    "print(len(word_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "laden-bedroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b087292710>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_counts = remove_rare_words_from_word_counts(word_counts)\n",
    "print(len(word_counts.keys()))\n",
    "plt.plot(sorted(word_counts.values(), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adapted-garbage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"n't\", 2522),\n",
       " ('people', 1987),\n",
       " ('think', 1796),\n",
       " ('going', 1617),\n",
       " ('president', 1408),\n",
       " ('would', 1384),\n",
       " ('one', 1096),\n",
       " ('get', 1059),\n",
       " ('make', 1016),\n",
       " ('want', 956),\n",
       " ('know', 943),\n",
       " ('country', 917),\n",
       " ('said', 912),\n",
       " ('uh', 910),\n",
       " ('years', 844),\n",
       " ('got', 800),\n",
       " ('us', 777),\n",
       " ('well', 763),\n",
       " ('say', 701),\n",
       " ('america', 693)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = [(k, v) for k, v in word_counts.items()]\n",
    "top_n = sorted(\n",
    "    pairs, key=lambda item: -item[1]\n",
    ")\n",
    "top_n[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "composed-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordmap = generate_wordmap(list(word_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "endangered-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: dropout?\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_dims):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dims, 500)\n",
    "        self.layer2 = nn.Linear(500, 75)\n",
    "        self.layer3 = nn.Linear(75, 1)\n",
    "\n",
    "    # Called on each input\n",
    "    # Computes the outputs (and next hidden state)\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x\n",
    "\n",
    "def validate(model, val_set):\n",
    "    val_x = []\n",
    "    val_y = []\n",
    "    for val_datum in val_set:\n",
    "        val_x.append(val_datum[1])\n",
    "        val_y.append(val_datum[2])\n",
    "    val_x = torch.FloatTensor([[list(map(\n",
    "        lambda string: string_to_vector(string, wordmap),\n",
    "        val_x\n",
    "    ))]])\n",
    "    val_outputs = neural_net(val_x)\n",
    "    loss = mse(val_outputs, torch.FloatTensor(val_y))\n",
    "    print(f'MSE Loss: {loss.item()}')\n",
    "    \n",
    "    outputs = []\n",
    "    for v_o in val_outputs[0][0]:\n",
    "        if v_o < -0.5:\n",
    "            outputs.append(-1)\n",
    "        elif v_o > 0.5:\n",
    "            outputs.append(1)\n",
    "        else:\n",
    "            outputs.append(0)\n",
    "\n",
    "    print(f'Macro F1: {metrics.f1_score(val_y, outputs, average=\"macro\")}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "running-relief",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0454]]]], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net = NeuralNet(len(wordmap))\n",
    "neural_net(torch.Tensor([[[string_to_vector('president think say',wordmap)]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "recent-salem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.0430]]]], grad_fn=<TanhBackward>), -1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net(torch.Tensor([[[string_to_vector(train_set[0][1],wordmap)]]])), train_set[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dimensional-sitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\thisi\\documents\\github\\make-my-story\\env\\lib\\site-packages\\torch\\nn\\modules\\loss.py:446: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([1, 1, 4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.720\n",
      "[1,  4000] loss: 0.720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\thisi\\documents\\github\\make-my-story\\env\\lib\\site-packages\\torch\\nn\\modules\\loss.py:446: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,  2000] loss: 0.705\n",
      "[2,  4000] loss: 0.724\n",
      "[3,  2000] loss: 0.708\n",
      "[3,  4000] loss: 0.709\n",
      "[4,  2000] loss: 0.704\n",
      "[4,  4000] loss: 0.708\n",
      "[5,  2000] loss: 0.720\n",
      "[5,  4000] loss: 0.687\n",
      "[6,  2000] loss: 0.702\n",
      "[6,  4000] loss: 0.708\n",
      "[7,  2000] loss: 0.702\n",
      "[7,  4000] loss: 0.707\n",
      "[8,  2000] loss: 0.704\n",
      "[8,  4000] loss: 0.704\n",
      "[9,  2000] loss: 0.700\n",
      "[9,  4000] loss: 0.708\n",
      "[10,  2000] loss: 0.705\n",
      "[10,  4000] loss: 0.707\n"
     ]
    }
   ],
   "source": [
    "mse = nn.MSELoss()\n",
    "optimizer = optim.SGD(neural_net.parameters(), lr=0.001, momentum=0.9)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        _, x, labels = data\n",
    "        \n",
    "        x = torch.FloatTensor([[list(map(\n",
    "            lambda string: string_to_vector(string, wordmap),\n",
    "            x\n",
    "        ))]])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = neural_net(x)\n",
    "        loss = mse(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "elder-istanbul",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 0.7793642282485962\n",
      "Macro F1: 0.21142681398656524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\thisi\\documents\\github\\make-my-story\\env\\lib\\site-packages\\torch\\nn\\modules\\loss.py:446: UserWarning: Using a target size (torch.Size([2000])) that is different to the input size (torch.Size([1, 1, 2000, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "validate(neural_net, val_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
