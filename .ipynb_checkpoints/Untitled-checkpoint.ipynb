{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "complicated-representative",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\thisi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\thisi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk.corpus\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn import metrics\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bright-question",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstopwords = stopwords + [\\n    \"n\\'t\",\\n    \\'not\\',\\n    \\'mr\\',\\n    \\'mr.\\'\\n]\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "'''\n",
    "stopwords = stopwords + [\n",
    "    \"n't\",\n",
    "    'not',\n",
    "    'mr',\n",
    "    'mr.'\n",
    "]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "western-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('train.csv', newline='', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, dialect='excel')\n",
    "    train_set = list(reader)\n",
    "\n",
    "train_set = list(map(\n",
    "    lambda x: (int(x[0]), x[1], int(x[2])),\n",
    "    train_set[1:]\n",
    "))\n",
    "\n",
    "random.shuffle(train_set)\n",
    "val_set = train_set[:2000]\n",
    "train_set = train_set[2000:]\n",
    "\n",
    "with open('test.csv', newline='', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, dialect='excel')\n",
    "    test_set = list(reader)\n",
    "\n",
    "test_set = list(map(\n",
    "    lambda x: (int(x[0]), x[1]),\n",
    "    test_set[1:]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "included-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_tokens(string):\n",
    "    tokens = word_tokenize(string)\n",
    "    tokens = filter(\n",
    "        lambda x: re.match(re.compile(r\"^[A-Za-z'][A-Za-z'.]*$\"), x),\n",
    "        tokens\n",
    "    )\n",
    "    tokens = map(\n",
    "        lambda x: x.lower(),\n",
    "        tokens\n",
    "    )\n",
    "    tokens = filter(\n",
    "        lambda x: x not in stopwords and x[0] != \"'\",\n",
    "        tokens\n",
    "    )\n",
    "    return list(tokens)\n",
    "\n",
    "def remove_unknown_words(vocab, tokens):\n",
    "    return list(filter(\n",
    "        lambda x: x in vocab,\n",
    "        tokens\n",
    "    ))\n",
    "\n",
    "def generate_word_counts(train_set):\n",
    "    word_counts = {}\n",
    "    for train_datum in train_set:\n",
    "        for word in string_to_tokens(train_datum[1]):\n",
    "            word_counts[word] = word_counts.get(word, 0) + 1\n",
    "    return word_counts\n",
    "\n",
    "def remove_rare_words_from_word_counts(word_counts, threshold=5):\n",
    "    new_dict = {}\n",
    "    for word in word_counts.keys():\n",
    "        if word_counts[word] >= threshold:\n",
    "            new_dict[word] = word_counts[word]\n",
    "    return new_dict\n",
    "\n",
    "# returns a dict that maps words to integers. will be used for encoding text.\n",
    "def generate_wordmap(words):\n",
    "    wordmap = {}\n",
    "    for i in range(len(words)):\n",
    "        wordmap[words[i]] = i\n",
    "    return wordmap\n",
    "\n",
    "def string_to_vector(string, wordmap):\n",
    "    tokens = string_to_tokens(string)\n",
    "    tokens = remove_unknown_words(wordmap.keys(), tokens)\n",
    "    result = np.zeros(len(wordmap))\n",
    "    for token in tokens:\n",
    "        result[wordmap[token]] += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "peaceful-capacity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10459\n"
     ]
    }
   ],
   "source": [
    "word_counts = generate_word_counts(train_set)\n",
    "print(len(word_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "laden-bedroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27af0ee6a58>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_counts = remove_rare_words_from_word_counts(word_counts)\n",
    "print(len(word_counts.keys()))\n",
    "plt.plot(sorted(word_counts.values(), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adapted-garbage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"n't\", 2534),\n",
       " ('people', 1978),\n",
       " ('think', 1832),\n",
       " ('going', 1600),\n",
       " ('president', 1412),\n",
       " ('would', 1407),\n",
       " ('one', 1097),\n",
       " ('get', 1068),\n",
       " ('make', 998),\n",
       " ('want', 974),\n",
       " ('know', 932),\n",
       " ('said', 915),\n",
       " ('uh', 908),\n",
       " ('country', 907),\n",
       " ('years', 846),\n",
       " ('got', 803),\n",
       " ('well', 763),\n",
       " ('us', 762),\n",
       " ('say', 704),\n",
       " ('tax', 699)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = [(k, v) for k, v in word_counts.items()]\n",
    "top_n = sorted(\n",
    "    pairs, key=lambda item: -item[1]\n",
    ")\n",
    "top_n[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "composed-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordmap = generate_wordmap(list(word_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "endangered-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: dropout?\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_dims):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dims, 500)\n",
    "        self.layer2 = nn.Linear(500, 75)\n",
    "        self.layer3 = nn.Linear(75, 1)\n",
    "\n",
    "    # Called on each input\n",
    "    # Computes the outputs (and next hidden state)\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x\n",
    "\n",
    "def validate(model, val_set):\n",
    "    val_x = []\n",
    "    val_y = []\n",
    "    for val_datum in val_set:\n",
    "        val_x.append(val_datum[1])\n",
    "        val_y.append(val_datum[2])\n",
    "    val_x = torch.FloatTensor([[list(map(\n",
    "        lambda string: string_to_vector(string, wordmap),\n",
    "        val_x\n",
    "    ))]])\n",
    "    val_outputs = neural_net(val_x)\n",
    "    loss = mse(val_outputs, torch.FloatTensor(val_y))\n",
    "    print(f'MSE Loss: {loss.item()}')\n",
    "    \n",
    "    outputs = []\n",
    "    for v_o in val_outputs[0][0]:\n",
    "        if v_o < -0.5:\n",
    "            outputs.append(-1)\n",
    "        elif v_o > 0.5:\n",
    "            outputs.append(1)\n",
    "        else:\n",
    "            outputs.append(0)\n",
    "\n",
    "    print(metrics.f1_score(val_y, outputs, average='macro'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "running-relief",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0008]]]], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net = NeuralNet(len(wordmap))\n",
    "neural_net(torch.Tensor([[[string_to_vector('president think say',wordmap)]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "recent-salem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.0004]]]], grad_fn=<TanhBackward>), -1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net(torch.Tensor([[[string_to_vector(train_set[0][1],wordmap)]]])), train_set[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-sitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.734\n",
      "[1,  4000] loss: 0.720\n",
      "[2,  2000] loss: 0.737\n",
      "[2,  4000] loss: 0.711\n",
      "[3,  2000] loss: 0.711\n",
      "[3,  4000] loss: 0.717\n",
      "[4,  2000] loss: 0.724\n",
      "[4,  4000] loss: 0.701\n",
      "[5,  2000] loss: 0.718\n",
      "[5,  4000] loss: 0.706\n",
      "[6,  2000] loss: 0.722\n",
      "[6,  4000] loss: 0.706\n",
      "[7,  2000] loss: 0.702\n",
      "[7,  4000] loss: 0.711\n",
      "[8,  2000] loss: 0.715\n",
      "[8,  4000] loss: 0.704\n"
     ]
    }
   ],
   "source": [
    "mse = nn.MSELoss()\n",
    "optimizer = optim.SGD(neural_net.parameters(), lr=0.001, momentum=0.9)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        _, x, labels = data\n",
    "        \n",
    "        x = torch.FloatTensor([[list(map(\n",
    "            lambda string: string_to_vector(string, wordmap),\n",
    "            x\n",
    "        ))]])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = neural_net(x)\n",
    "        loss = mse(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "elder-istanbul",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\thisi\\documents\\github\\make-my-story\\env\\lib\\site-packages\\torch\\nn\\modules\\loss.py:446: UserWarning: Using a target size (torch.Size([2000])) that is different to the input size (torch.Size([1, 1, 2000, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 0.9013282656669617\n",
      "> \u001b[1;32m<ipython-input-43-161928d4ed8d>\u001b[0m(45)\u001b[0;36mvalidate\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     42 \u001b[1;33m            \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     43 \u001b[1;33m    \u001b[1;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     44 \u001b[1;33m    \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 45 \u001b[1;33m    \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     46 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> outputs\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "ipdb> val_y\n",
      "[-1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, -1, -1, 0, -1, 1, 0, -1, -1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, -1, -1, 0, 1, 1, 0, 1, 0, 1, 1, -1, -1, -1, 1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, 1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, 1, -1, -1, -1, 0, 1, 1, 0, -1, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, 1, 0, -1, -1, 0, 1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, 1, -1, -1, 0, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 1, -1, -1, -1, 0, 1, -1, 1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, 1, 1, -1, 0, 1, 1, 1, -1, 1, -1, -1, -1, -1, 0, -1, 1, 1, 0, 1, -1, 1, -1, 1, -1, -1, 1, -1, 0, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, 0, -1, 1, -1, -1, 0, -1, -1, 0, -1, -1, -1, 1, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 1, -1, 1, -1, -1, -1, 0, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, 1, -1, -1, -1, 0, 0, 1, 1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 0, 1, -1, 0, 1, 1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 0, -1, 1, 1, -1, -1, 0, -1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, 1, 0, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, 0, 1, -1, -1, -1, 1, -1, -1, 0, -1, -1, 1, -1, -1, 1, -1, -1, 1, -1, 0, 1, -1, 1, -1, -1, -1, 0, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 0, 1, -1, 0, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 1, 1, -1, -1, 0, 1, -1, -1, -1, 1, 1, 1, 0, 1, -1, 0, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, 0, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, 1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, 1, 1, 0, -1, -1, 1, -1, -1, -1, -1, 1, 0, -1, 1, -1, -1, -1, 1, 0, 1, 1, -1, 0, -1, 1, -1, 0, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 0, -1, 1, -1, 0, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, 1, -1, 0, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, 0, 0, -1, -1, -1, 0, 0, 0, 0, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, 1, 0, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 0, 0, -1, 1, 1, 0, 0, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 0, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, 1, -1, 1, -1, -1, 1, 0, 0, -1, 1, 0, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, 0, 1, 0, -1, -1, 0, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, 1, -1, 0, 0, 1, 1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, 1, -1, -1, 1, 0, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, 1, 0, 1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, 0, -1, 1, 1, -1, -1, 0, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, 1, 1, 1, 0, 0, 0, -1, -1, -1, -1, 1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, 0, -1, -1, -1, 1, -1, -1, -1, 1, -1, 1, -1, 1, -1, -1, 1, 0, 1, 1, -1, -1, -1, 0, -1, -1, -1, -1, 1, -1, -1, 0, -1, -1, -1, -1, -1, -1, 1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, 1, -1, 1, -1, 0, -1, 1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 0, 1, -1, -1, 0, -1, 1, -1, -1, -1, 0, -1, 1, 1, -1, -1, 0, 1, -1, -1, 1, 0, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, 0, -1, -1, -1, -1, 0, 0, 0, -1, 0, -1, -1, 1, 1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, -1, -1, 1, 0, -1, 0, -1, 1, -1, 1, 0, -1, 1, -1, 1, -1, -1, 1, -1, 1, 0, 0, -1, 1, -1, 1, 0, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, 1, 1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, 1, -1, 0, 0, -1, 0, 0, 0, 1, 1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, 1, -1, 0, -1, 0, 1, 1, 1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 0, -1, 1, 0, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, -1, 1, 0, -1, -1, -1, -1, -1, -1, 0, 1, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, -1, 1, 0, -1, -1, -1, 0, -1, -1, 1, 1, 1, -1, -1, -1, 1, 1, -1, -1, -1, 1, 1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 1, 1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, -1, 1, -1, 1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 0, 0, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, 1, 1, -1, 1, -1, 1, -1, -1, 1, -1, 0, 1, -1, -1, 0, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, 1, 1, 0, -1, 1, -1, -1, -1, 1, -1, -1, 1, -1, -1, 1, 1, -1, -1, -1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, 1, -1, -1, -1, 0, -1, -1, 1, -1, 0, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 0, -1, 0, 1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, 0, 1, 1, 1, 1, -1, 0, -1, -1, -1, 1, 0, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, -1, 0, -1, -1, -1, -1, 1, -1, -1, 0, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 0, -1, -1, -1, 0, -1, -1, -1, -1, 1, -1, 1, 0, -1, 1, 1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, 0, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, 1, -1, 1, 1, -1, 1, -1, 0, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 0, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 0, 1, -1, -1, -1, -1, -1, 0, -1, 1, -1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, 1, -1, 0, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1, 1, -1, 0, -1, -1, 0, -1, -1, 1, 0, -1, -1, -1, -1, -1, 0, -1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, 1, 1, 1, 0, -1, 1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 0, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 1, -1, 0, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> type(val_y)\n",
      "<class 'list'>\n",
      "ipdb> type(outputs)\n",
      "<class 'list'>\n",
      "ipdb> exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-9d34beb5d9e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneural_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-43-161928d4ed8d>\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(model, val_set)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-161928d4ed8d>\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(model, val_set)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python3.6\\lib\\bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;31m# None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'line'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'call'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python3.6\\lib\\bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "validate(neural_net, val_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
